
# ğŸ“š Amazon Hybrid Book Recommendation System

This project implements a **hybrid recommendation engine** for books using the [Amazon Books Reviews dataset](https://www.kaggle.com/datasets/mohamedbakhet/amazon-books-reviews).

It combines:

* **Content-Based Filtering** â†’ NLP on summaries, categories, and metadata.
* **Collaborative Filtering** â†’ userâ€“item matrix + nearest neighbors.
* **Embedding-Based Retrieval** â†’ fast approximate nearest neighbors with Annoy.

---

## ğŸ’¡ About Hybrid Recommender Systems

Recommender systems usually fall into two categories:

* **Content-Based**: Recommend items similar to what the user liked, based on text/content.
* **Collaborative Filtering**: Recommend items based on userâ€“item interactions.

âš¡ This project **blends both approaches**.

* Users get recommendations that are **semantically similar (via NLP)**
* AND aligned with **community behavior (via collaborative filtering)**
* While **Annoy index** ensures scalable and fast lookup.

---

## ğŸ“ Dataset Overview

We use the [`mohamedbakhet/amazon-books-reviews`](https://www.kaggle.com/datasets/mohamedbakhet/amazon-books-reviews) dataset:

* Over **10 million records** (â‰ˆ1 GB+ uncompressed)
* Fields:

  * `User_id` â€“ reviewer
  * `Title` â€“ book title
  * `review/score` â€“ numeric rating
  * `review/summary` â€“ short review text
  * `categories`, `authors`, `description` â€“ metadata

â¡ï¸ Due to space/memory constraints, we **sample 10%** of the dataset for experimentation.

---

## ğŸ§ª Execution Modes

### âœ… 1. Sampled Dataset (Faster, Lightweight)

A preprocessed sample (`ratings2_processed.csv`) is included.
Run the script:

```bash
python hybrid_model.py
```

This will:

* Load the sample
* Clean/normalize titles, categories, authors
* Process summaries/descriptions with **NLTK + lemmatization**
* Build **TF-IDF + SVD embeddings**
* Train **collaborative models**
* Index books with **Annoy**
* Generate recommendations

---

### âš™ï¸ 2. Full Pipeline From Scratch

You can also run the full pipeline on the **original Kaggle dataset**.

Steps include:

* Download via `kagglehub`
* **Randomly sample 10%** of records
* Clean noisy titles with regex + fuzzy matching (RapidFuzz)
* Normalize metadata (`categories`, `authors`)
* Clean and lemmatize review summaries + compute sentiment (NLTK VADER)
* Vectorize with **TF-IDF + dimensionality reduction (SVD)**
* Build hybrid recommendation models

This mode is heavier but ensures full reproducibility.

---

## ğŸ§¹ Data Cleaning Highlights

* ğŸ“ **Title Normalization** â†’ lowercase, remove punctuation, normalize variants like *The Lord of the Rings*.
* ğŸ” **Fuzzy Deduplication** â†’ merge duplicate titles via RapidFuzz.
* ğŸ“‚ **Metadata Cleaning** â†’ authors/categories stripped & standardized.
* ğŸ§¾ **Text Preprocessing** â†’ tokenization, stopword removal, lemmatization.
* ğŸ˜Š **Sentiment Analysis** â†’ NLTK VADER scores included as features.

---

## ğŸ” Feature Engineering

* ğŸ“– **TF-IDF on cleaned summaries & descriptions**
* ğŸ”½ **Truncated SVD** â†’ reduces dimensionality for scalability
* âš¡ **Annoy Index** â†’ fast approximate nearest neighbors for book retrieval
* ğŸ˜Š **Sentiment scores** used to enrich recommendation quality

---

## ğŸ”„ Recommendations

### ğŸ“Œ Content-Based

* Find semantically similar books (via TF-IDF + cosine similarity).

### ğŸ‘¥ Collaborative

* Use **userâ€“item rating matrix** + **KNN** to recommend books based on similar users.

### âš¡ Hybrid (Final Model)

* Combines content similarity + collaborative scores.
* Annoy index speeds up recommendations across millions of items.

---

## ğŸ“Š Evaluation

* Precision\@k and Recall\@k for collaborative filtering.
* Qualitative case studies for hybrid recommendations.
* Fast inference benchmarks using Annoy.

---

## ğŸ“¦ Dependencies

Install via pip:

```bash
pip install pandas numpy matplotlib seaborn nltk scikit-learn rapidfuzz annoy kagglehub
```

Download NLTK resources:

```python
nltk.download("punkt")
nltk.download("stopwords")
nltk.download("wordnet")
nltk.download("vader_lexicon")
```

---

## â–¶ï¸ Running the Project

### 1. With Sampled Dataset

```bash
python hybrid_model.py
```

### 2. With Full Dataset

```bash
python hybrid_model.py --full
```

This will:

* Download the Kaggle dataset
* Sample, clean, and preprocess
* Save a smaller processed file for reuse

---

## ğŸ“Š Sample Output

```bash
Top-5 similar books to "Harry Potter":
 1. Harry Potter and the Chamber of Secrets
 2. The Lord of the Rings
 3. Percy Jackson & the Olympians
 ...

Hybrid recommendations for user A12345XYZ:
 - The Hobbit (score: 0.92)
 - The Catcher in the Rye (score: 0.87)
 - Pride and Prejudice (score: 0.84)
```

---

## ğŸ’» Author

**Reihane Montazeri** â€” Computer Engineer, ML/DL & Data Science Enthusiast
